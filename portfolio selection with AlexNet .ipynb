{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from multiprocessing import Pool, cpu_count # Multiprocessing package, speed up the process to get samples\n",
    "import numexpr as ne # Fast way to navigate and search in pd.DataFrame objects\n",
    "import time # Time the program\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, SeparableConv2D, SeparableConv1D, MaxPooling1D, MaxPooling2D, Flatten,\\\n",
    "                         Dense, Activation, Dropout\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad, SGD\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.conv_utils import normalize_data_format\n",
    "\n",
    "from keras.utils import conv_utils\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this class from 'get training and testing samples.ipynb'\n",
    "# Otherwise, will not be able to load in data (pickles of lists of instances of CNNSamples) previously saved\n",
    "\n",
    "class CNNSamples:\n",
    "    \n",
    "    def __init__(self, stockData, \n",
    "               data_len=64, \n",
    "               image_size=16, \n",
    "               retrain_freq=5):\n",
    "\n",
    "        self.permno = stockData.PERMNO.iloc[0]\n",
    "        self.data = stockData.drop('PERMNO', axis=1).T\n",
    "        self.data_len = data_len\n",
    "        self.image_size = image_size\n",
    "        self.retrain_freq = retrain_freq\n",
    "        self.GADFSample, self.GASFSample = [], []\n",
    "        self.nDays = self.data.shape[1]\n",
    "        self.nSamples = 0\n",
    "    \n",
    "    \n",
    "    def getTimeSeriesCNNSample(self):\n",
    "        \n",
    "        gadf, gasf = GADF(self.image_size), GASF(self.image_size)\n",
    "\n",
    "        for i in range(self.data_len, self.nDays, self.retrain_freq):\n",
    "            series = self.data.iloc[:, i-self.data_len:i]\n",
    "            self.GADFSample.append(gadf.fit_transform(series).T)\n",
    "            self.GASFSample.append(gasf.fit_transform(series).T)\n",
    "\n",
    "        self.nSamples = len(self.GADFSample)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingDataFromPath(feature_path = '/Volumes/Seagate Backup Plus Drive/deep learning data/'+ \\\n",
    "                                            str(image_size)+'-pixel/',\n",
    "                            target_path = '/Volumes/Seagate Backup Plus Drive/deep learning data/target/',\n",
    "                            data_type = 'GADF',\n",
    "                            image_size = 16,\n",
    "                            train_val_size = 2/3,\n",
    "                            train_size = 0.75):\n",
    "    \n",
    "    \"\"\" This function helps load in all TS-Image samples, and organize them into trainable manner. \n",
    "        Parameters explained:\n",
    "        \n",
    "        1) feature_path, target_path:\n",
    "            Path for saved data. 'feature_path': X data; 'target_path': Y data.\n",
    "            Notice: X data has to be named as 'CNNSamples_1', 'CNNSamples_2', ... etc.\n",
    "                    Y data has to be named as 'CNNSamples_target'\n",
    "                    \n",
    "        2) data_type:\n",
    "            Takes value only from one of 'GADF' and 'GASF'. Specify the type of TS-Image type.\n",
    "        \n",
    "        3) image_size:\n",
    "            Image_size of each sample.\n",
    "            \n",
    "        4) train_val_size:\n",
    "            Portion of sample taken to do training+validation\n",
    "        \n",
    "        5) train_size:\n",
    "            Portion of sample taken from training+validation data to do training\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    data_file_num = len(os.listdir(feature_path)) - 1\n",
    "    all_data = []\n",
    "    for i in range(data_file_num):\n",
    "        with open(feature_path+'CNNSamples_'+str(i+1), 'rb') as pick:\n",
    "            all_data += pickle.load(pick)\n",
    "            pick.close()\n",
    "    \n",
    "    X = []\n",
    "    if data_type == 'GADF':\n",
    "        for obj in all_data:\n",
    "            X += (obj.GADFSample[:int(obj.nSamples*train_val_size)+1])\n",
    "    else:\n",
    "        for obj in all_data:\n",
    "            X += (obj.GASFSample[:int(obj.nSamples*train_val_size)+1])\n",
    "    \n",
    "    X = np.array(X).reshape((len(all_data)*len(obj.nSamples), image_size, image_size, 4))\n",
    "    \n",
    "    with open(target_path+'CNNSamples_target', 'rb') as pick2:\n",
    "        Ytmp = pickle.load(pick2)\n",
    "        pick2.close()\n",
    "        \n",
    "    Y = np.array([y[1][:int(obj.nSamples*train_val_size)+1] for y in Ytmp]).reshape((len(X), 3))\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, train_size=train_size, shuffle=False)\n",
    "    \n",
    "    return (X_train, X_val, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = getTrainingDataFromPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 740137\n",
      "validation set size: 246713\n",
      "number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "print('training set size:', len(X_train))\n",
    "print('validation set size:', len(X_val))\n",
    "print('number of classes:', Y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "historical data distribution: [0.37615063 0.27406142 0.34978794]\n",
      "validation data distribution: [0.39027939 0.24492832 0.36479229]\n"
     ]
    }
   ],
   "source": [
    "print('historical data distribution:', Y_train.sum(axis=0)/len(Y_train))\n",
    "print('validation data distribution:', Y_val.sum(axis=0)/len(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed AlexNet\n",
    "AlexNet defined below. <br>\n",
    "Instead of a network structure with Original AlexNet (2014):<br>\n",
    "Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Conv2D$\\rightarrow$Conv2D$\\rightarrow$Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Dropout$\\rightarrow$FullyConnected$\\rightarrow$Dropout$\\rightarrow$FullyConnected$\\rightarrow$Dropout$\\rightarrow$Output<br><br>\n",
    "its architecture is now both parametrically and layer reduced:<br>\n",
    "Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Conv2D$\\rightarrow$MaxPooling2D$\\rightarrow$Dropout$\\rightarrow$FullyConnected$\\rightarrow$Dropout$\\rightarrow$FullyConnected$\\rightarrow$Dropout$\\rightarrow$Output<br>\n",
    "In other words, two convolutional layers are dropped from original AlexNet, to account for the fact that image size is much smaller in my case. Also, the pool_size, strides, filters are all reduced to make my case more paramatrically parsimonious. Activation 'tanh' is used, to map data to [-1,1], which makes more sense for time-series. Also, zero padding is used to preserve more information over each layer.<br><br>\n",
    "Apart from the architecture changes, max pooling method is modified to account for difference of image and TS-Image. Generally, MaxPooling2D output the largest element from the block it filters. Now I define a new kind of pooling layer called MaxAbsPooling2D, which outputs the value with largest absolute value (but sign-preserving). This is to account for the fact that strong negative correlation of time series also plays an important role in forecasting time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAbsPooling2D(Layer):\n",
    "    \n",
    "    \"\"\"Max Absolute value pooling\n",
    "    \n",
    "    Derived Layer class\n",
    "    The pooling operation is defined in member function '_pooling_function'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size=(2, 2), strides=None, padding='same',\n",
    "                 data_format='channels_last', **kwargs):\n",
    "        super(MaxAbsPooling2D, self).__init__(**kwargs)\n",
    "        if strides is None:\n",
    "            strides = pool_size\n",
    "        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = normalize_data_format(data_format)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            rows = input_shape[2]\n",
    "            cols = input_shape[3]\n",
    "        elif self.data_format == 'channels_last':\n",
    "            rows = input_shape[1]\n",
    "            cols = input_shape[2]\n",
    "        rows = conv_utils.conv_output_length(rows, self.pool_size[0],\n",
    "                                             self.padding, self.strides[0])\n",
    "        cols = conv_utils.conv_output_length(cols, self.pool_size[1],\n",
    "                                             self.padding, self.strides[1])\n",
    "        if self.data_format == 'channels_first':\n",
    "            return (input_shape[0], input_shape[1], rows, cols)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            return (input_shape[0], rows, cols, input_shape[3])\n",
    "\n",
    "    def _pooling_function(self, inputs, pool_size, strides,\n",
    "                              padding, data_format):\n",
    "        \n",
    "        # Output the original maxpooling2d first\n",
    "        # Output a maxpooling2d on abs(inputs)\n",
    "        # Find the difference between two outputs, where negative numbers have larger absolute values\n",
    "        # Multiply the boolean matrix representing difference with the second output and get the signed pooled outputs\n",
    "        \n",
    "        output1 = K.pool2d(inputs, pool_size, strides,\n",
    "                           padding, data_format,\n",
    "                           pool_mode='max')\n",
    "        output2 = K.pool2d(K.abs(inputs), pool_size, strides,\n",
    "                           padding, data_format,\n",
    "                           pool_mode='max')\n",
    "        difference = 2*K.cast(K.equal(output1, output2), dtype=float)-1\n",
    "        output =(output2*difference)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = self._pooling_function(inputs=inputs,\n",
    "                                        pool_size=self.pool_size,\n",
    "                                        strides=self.strides,\n",
    "                                        padding=self.padding,\n",
    "                                        data_format=self.data_format)\n",
    "        return output\n",
    "\n",
    "\n",
    "class getPredictionAfterEpoch(Callback):\n",
    "    \n",
    "    \"\"\"Callback that records prediction on validation data over epochs of training\n",
    "       To call bayesian neural network method, one just average the prediction from last N epochs of neural net\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.outputs.append(self.model.predict(self.validation_data[0]))\n",
    "\n",
    "\n",
    "\n",
    "class CondensedAlexNet:\n",
    "    def __init__(self,\n",
    "                image_size=16, \n",
    "                channel_size=4,\n",
    "                nClass=3,\n",
    "                filters=[6, 8, 4], \n",
    "                kernel_size=[2, 2, 2], \n",
    "                pool_size=[2, 2, 2],\n",
    "                strides=[1, 1, 1, 1, 1, 1],\n",
    "                MaxAbsPool=True, \n",
    "                padding=['same']*8, \n",
    "                conv_activation='tanh',\n",
    "                denseNeurons=[64, 20], \n",
    "                dropout=0.2,\n",
    "                dense_activation='tanh',\n",
    "                isBayesian=False):\n",
    "        \n",
    "        self.nClass = nClass\n",
    "        self.image_size = image_size\n",
    "        self.channel_size = channel_size\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "        self.MaxAbsPool = MaxAbsPool\n",
    "        self.padding = padding\n",
    "        self.conv_activation = conv_activation\n",
    "        self.denseNeurons = denseNeurons\n",
    "        self.dropout = dropout\n",
    "        self.dense_activation = dense_activation\n",
    "        self.isBayesian = isBayesian\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(input_shape=(self.image_size, self.image_size, self.channel_size), \n",
    "                              filters=self.filters[0], kernel_size=(self.kernel_size[0], self.kernel_size[0]),\n",
    "                              strides=(self.strides[0], self.strides[0]), data_format='channels_last',\n",
    "                              activation=self.conv_activation, padding=self.padding[0]))\n",
    "        \n",
    "        self.model.add(MaxPooling2D(pool_size=(self.pool_size[0],self.pool_size[0]), \n",
    "                                       strides=(self.strides[1],self.strides[1]), padding=self.padding[1]))\n",
    "        \n",
    "        self.model.add(Conv2D(filters=self.filters[1], kernel_size=(self.kernel_size[1], self.kernel_size[1]),\n",
    "                              strides=(self.strides[2], self.strides[2]),\n",
    "                              activation=self.conv_activation, padding=self.padding[2]))\n",
    "        \n",
    "        self.model.add(MaxPooling2D(pool_size=(self.pool_size[1],self.pool_size[1]), \n",
    "                                       strides=(self.strides[3],self.strides[3]), padding=self.padding[3]))\n",
    "        \n",
    "        self.model.add(Conv2D(filters=self.filters[2], kernel_size=(self.kernel_size[2], self.kernel_size[2]),\n",
    "                              strides=(self.strides[4], self.strides[4]),\n",
    "                              activation=self.conv_activation, padding=self.padding[4]))\n",
    "        \n",
    "        self.model.add(MaxPooling2D(pool_size=(self.pool_size[2],self.pool_size[2]), \n",
    "                                       strides=(self.strides[5],self.strides[5]), padding=self.padding[5]))\n",
    "        \n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        \n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        self.model.add(Dense(self.denseNeurons[0], activation=self.dense_activation))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(Dense(self.denseNeurons[1], activation=self.dense_activation))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(Dense(self.nClass, activation='softmax'))\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True),\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y, valX=None, valY=None, verbose=1, epochs=20, batch_size=256):\n",
    "        \n",
    "        if self.isBayesian:\n",
    "            self.myCallBack = getPredictionAfterEpoch()\n",
    "            self.model.fit(X,Y, validation_data=(valX, valY),\n",
    "                           epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[self.myCallBack])\n",
    "    \n",
    "        else:\n",
    "            self.myCallBack = None\n",
    "            self.model.fit(X,Y, validation_data=(valX, valY),\n",
    "                           epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def predict_classes(self, x):\n",
    "        return self.model.predict_classes(x)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 740137 samples, validate on 246713 samples\n",
      "Epoch 1/20\n",
      "740137/740137 [==============================] - 652s 882us/step - loss: 1.0726 - acc: 0.4314 - val_loss: 1.0543 - val_acc: 0.4606\n",
      "Epoch 2/20\n",
      "740137/740137 [==============================] - 602s 813us/step - loss: 1.0614 - acc: 0.4476 - val_loss: 1.0527 - val_acc: 0.4628\n",
      "Epoch 3/20\n",
      "740137/740137 [==============================] - 590s 797us/step - loss: 1.0594 - acc: 0.4500 - val_loss: 1.0493 - val_acc: 0.4648\n",
      "Epoch 4/20\n",
      "740137/740137 [==============================] - 574s 776us/step - loss: 1.0581 - acc: 0.4513 - val_loss: 1.0502 - val_acc: 0.4640\n",
      "Epoch 5/20\n",
      "740137/740137 [==============================] - 588s 795us/step - loss: 1.0573 - acc: 0.4516 - val_loss: 1.0475 - val_acc: 0.4655\n",
      "Epoch 6/20\n",
      "740137/740137 [==============================] - 600s 811us/step - loss: 1.0567 - acc: 0.4520 - val_loss: 1.0478 - val_acc: 0.4668\n",
      "Epoch 7/20\n",
      "740137/740137 [==============================] - 581s 785us/step - loss: 1.0562 - acc: 0.4523 - val_loss: 1.0488 - val_acc: 0.4663\n",
      "Epoch 8/20\n",
      "740137/740137 [==============================] - 594s 802us/step - loss: 1.0560 - acc: 0.4524 - val_loss: 1.0477 - val_acc: 0.4647\n",
      "Epoch 9/20\n",
      "740137/740137 [==============================] - 620s 838us/step - loss: 1.0554 - acc: 0.4533 - val_loss: 1.0473 - val_acc: 0.4650\n",
      "Epoch 10/20\n",
      "740137/740137 [==============================] - 613s 828us/step - loss: 1.0553 - acc: 0.4531 - val_loss: 1.0456 - val_acc: 0.4669\n",
      "Epoch 11/20\n",
      "740137/740137 [==============================] - 557s 752us/step - loss: 1.0548 - acc: 0.4532 - val_loss: 1.0471 - val_acc: 0.4670\n",
      "Epoch 12/20\n",
      "740137/740137 [==============================] - 577s 780us/step - loss: 1.0546 - acc: 0.4536 - val_loss: 1.0464 - val_acc: 0.4668\n",
      "Epoch 13/20\n",
      "740137/740137 [==============================] - 1051s 1ms/step - loss: 1.0544 - acc: 0.4536 - val_loss: 1.0466 - val_acc: 0.4659\n",
      "Epoch 14/20\n",
      "740137/740137 [==============================] - 612s 826us/step - loss: 1.0541 - acc: 0.4535 - val_loss: 1.0452 - val_acc: 0.4669\n",
      "Epoch 15/20\n",
      "740137/740137 [==============================] - 577s 780us/step - loss: 1.0542 - acc: 0.4539 - val_loss: 1.0481 - val_acc: 0.4614\n",
      "Epoch 16/20\n",
      "740137/740137 [==============================] - 562s 759us/step - loss: 1.0541 - acc: 0.4538 - val_loss: 1.0434 - val_acc: 0.4672\n",
      "Epoch 17/20\n",
      "740137/740137 [==============================] - 560s 756us/step - loss: 1.0539 - acc: 0.4535 - val_loss: 1.0457 - val_acc: 0.4671\n",
      "Epoch 18/20\n",
      "740137/740137 [==============================] - 591s 798us/step - loss: 1.0538 - acc: 0.4538 - val_loss: 1.0444 - val_acc: 0.4674\n",
      "Epoch 19/20\n",
      "740137/740137 [==============================] - 565s 764us/step - loss: 1.0539 - acc: 0.4532 - val_loss: 1.0457 - val_acc: 0.4671\n",
      "Epoch 20/20\n",
      "740137/740137 [==============================] - 569s 769us/step - loss: 1.0538 - acc: 0.4537 - val_loss: 1.0441 - val_acc: 0.4663\n"
     ]
    }
   ],
   "source": [
    "an = CondensedAlexNet()\n",
    "an.fit(X = X_train, Y = Y_train, valX = X_val, valY = Y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 740137 samples, validate on 246713 samples\n",
      "Epoch 1/20\n",
      "740137/740137 [==============================] - 1050s 1ms/step - loss: 1.0638 - acc: 0.4420 - val_loss: 1.0475 - val_acc: 0.4654\n",
      "Epoch 2/20\n",
      "740137/740137 [==============================] - 498s 673us/step - loss: 1.0538 - acc: 0.4549 - val_loss: 1.0425 - val_acc: 0.4679\n",
      "Epoch 3/20\n",
      "740137/740137 [==============================] - 519s 701us/step - loss: 1.0521 - acc: 0.4564 - val_loss: 1.0432 - val_acc: 0.4684\n",
      "Epoch 4/20\n",
      "740137/740137 [==============================] - 22066s 30ms/step - loss: 1.0511 - acc: 0.4568 - val_loss: 1.0410 - val_acc: 0.4679\n",
      "Epoch 5/20\n",
      "740137/740137 [==============================] - 523s 706us/step - loss: 1.0502 - acc: 0.4580 - val_loss: 1.0395 - val_acc: 0.4705\n",
      "Epoch 6/20\n",
      "740137/740137 [==============================] - 546s 738us/step - loss: 1.0500 - acc: 0.4578 - val_loss: 1.0439 - val_acc: 0.4658\n",
      "Epoch 7/20\n",
      "740137/740137 [==============================] - 541s 731us/step - loss: 1.0496 - acc: 0.4587 - val_loss: 1.0458 - val_acc: 0.4637\n",
      "Epoch 8/20\n",
      "740137/740137 [==============================] - 553s 747us/step - loss: 1.0492 - acc: 0.4590 - val_loss: 1.0386 - val_acc: 0.4718\n",
      "Epoch 9/20\n",
      "740137/740137 [==============================] - 558s 754us/step - loss: 1.0489 - acc: 0.4588 - val_loss: 1.0399 - val_acc: 0.4703\n",
      "Epoch 10/20\n",
      "740137/740137 [==============================] - 550s 743us/step - loss: 1.0485 - acc: 0.4597 - val_loss: 1.0381 - val_acc: 0.4702\n",
      "Epoch 11/20\n",
      "740137/740137 [==============================] - 550s 743us/step - loss: 1.0483 - acc: 0.4594 - val_loss: 1.0404 - val_acc: 0.4685\n",
      "Epoch 12/20\n",
      "740137/740137 [==============================] - 542s 733us/step - loss: 1.0479 - acc: 0.4595 - val_loss: 1.0381 - val_acc: 0.4714\n",
      "Epoch 13/20\n",
      "740137/740137 [==============================] - 554s 748us/step - loss: 1.0478 - acc: 0.4599 - val_loss: 1.0374 - val_acc: 0.4715\n",
      "Epoch 14/20\n",
      "740137/740137 [==============================] - 551s 745us/step - loss: 1.0476 - acc: 0.4604 - val_loss: 1.0390 - val_acc: 0.4710\n",
      "Epoch 15/20\n",
      "740137/740137 [==============================] - 509s 688us/step - loss: 1.0473 - acc: 0.4605 - val_loss: 1.0379 - val_acc: 0.4714\n",
      "Epoch 16/20\n",
      "740137/740137 [==============================] - 504s 681us/step - loss: 1.0474 - acc: 0.4601 - val_loss: 1.0397 - val_acc: 0.4684\n",
      "Epoch 17/20\n",
      "740137/740137 [==============================] - 556s 751us/step - loss: 1.0471 - acc: 0.4606 - val_loss: 1.0437 - val_acc: 0.4677\n",
      "Epoch 18/20\n",
      "740137/740137 [==============================] - 556s 752us/step - loss: 1.0470 - acc: 0.4604 - val_loss: 1.0402 - val_acc: 0.4702\n",
      "Epoch 19/20\n",
      "740137/740137 [==============================] - 554s 749us/step - loss: 1.0471 - acc: 0.4603 - val_loss: 1.0401 - val_acc: 0.4697\n",
      "Epoch 20/20\n",
      "740137/740137 [==============================] - 555s 750us/step - loss: 1.0469 - acc: 0.4605 - val_loss: 1.0383 - val_acc: 0.4713\n"
     ]
    }
   ],
   "source": [
    "an_maxpool = CondensedAlexNet()\n",
    "an_maxpool.fit(X = X_train, Y = Y_train, valX = X_val, valY = Y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
